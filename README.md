# python-data
 --------------------------
Вам необходимо сгенерировать свой датасет или выбрать любой публичный датасет имеющий
не менее 100 млн записей. Если не получается сделать расчеты на таком объеме - можно уменьшить размер.
имеющий колонки различных типов данных - numeric, datetime (range в несколько лет), string.
достаточно минимального набора колонок, чтобы датафайл был не сильно большой.
имеющий не менее 10% дублей (допускается добавить их самостоятельно)
хранящийся в csv / json формате в файле на диске или по url

------------------------------------

Считываем файл или тянем данные по ссылке и далее процессим данные
удалить пустые / na строки
удалить дубли
строки в которых нет цифр превратить в пустые
удалить записи в промежутке от 1 до 3 часов ночи
Для ускорения выполнения распараллеливайте выполнение этих шагов

------------------------------------

Расчет метрик
Агрегация по времени, для каждого часа рассчитать
кол-во уникальных string
среднее и медиану для numeric
Так же напишите SQL запрос для выполнения подобных расчетов напрямую в базе данных. Можно его вставить в код в виде комментария.

------------------------------------

Мерж с метриками
К каждой строке в исходном датасете примержить метрики ближайшего часа рассчитанные в предыдущем шаге

------------------------------------

Аналитические метрики
Для колонки numeric по полному датасету построить
Гистограмму
95% доверительный интервал, с комментарием как выбирали методику расчета

------------------------------------

Визуализация
Отрисовать график среднего значения numeric колонки (y) по месяцам (x).
Heatmap по частотности символов в колонке string
